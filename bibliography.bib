@inproceedings{Huan:2003:EMF:951949.952101,
 author = {Huan, Jun and Wang, Wei and Prins, Jan},
 title = {Efficient Mining of Frequent Subgraphs in the Presence of Isomorphism},
 booktitle = {Proceedings of the Third IEEE International Conference on Data Mining},
 series = {ICDM '03},
 year = {2003},
 isbn = {0-7695-1978-4},
 pages = {549--},
 url = {http://dl.acm.org/citation.cfm?id=951949.952101},
 acmid = {952101},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
	annote = {

FFSM is the proposed frequent subgraph mining algorithm of this work, operating on labeled undirected transaction graphs in a breadth-first search manner.
The targeted goal is to eliminate redundantly-generated subgraphs while the search space is traversed, thereby reducing the algorithm's runtime.
This is accomplished through the usage of the proposed canonical adjacency matrix (CAM) as a means of uniquely representing a graph.
Each graph is represented as an adjacency matrix with (non)diagonal elements corresponding to (edge) node labels.
The CAM of a graph is simply the lexicographic-maximal encoding of the graph, whereby a graph is encoded by concatenating the lower-triangular entries into a flat string.
This scheme offers useful properties that permit simple relationships between a represented graph and its subgraphs, leading to efficient supergraph generation from one or two subgraphs through joins and extensions and quick pruning if a generated supergraph is not in CAM form.
In performing joins and extensions iteratively, a CAM tree is generated in a BFS manner, traversing and pruning the search space of candidate subgraphs in such a way as to prevent duplicate generated candidates.

\\ \\

In terms of quality, this paper needs to further elaborate on the join and extension operations as well as the usefulness of a CAM's embedding set, as it is unclear how these operations and concepts are performed and useful.
Most of the rigorous material is relocated into a non-peer reviewed technical report, including the proofs of a theorem and several important corollaries and procedural pseudocode used in the main algorithm.
The experimental evaluation of FFSM indicates that its runtimes beat those of gSpan, although only one set of experiments is demonstrated in this paper with further experiments detailed in the aforementioned technical report.

	}
} 


@INPROCEEDINGS{1184038, 
	author={Xifeng Yan and Jiawei Han}, 
	booktitle={2002 IEEE International Conference on Data Mining, 2002. Proceedings.}, 
	title={gSpan: graph-based substructure pattern mining}, 
	year={2002}, 
	pages={721-724}, 
	keywords={data mining;tree searching;algorithm;canonical label;depth-first search strategy;frequent connected subgraph mining;frequent graph-based pattern mining;frequent substructure discovery;gSpan;graph datasets;graph-based substructure pattern mining;lexicographic order;performance study;unique minimum DFS code;Chemical compounds;Computer science;Costs;Data mining;Data structures;Graphics;Itemsets;Kernel;Testing;Tree graphs}, 
	doi={10.1109/ICDM.2002.1184038}, 
	month={},
	annote = {

The gSpan algorithm targets undirected transaction graph datasets to find frequent subgraphs in a depth-first search manner.
The main contribution of this paper is their new canonical labeling system, which is based on a code generated by a DFS traversal of a graph.
To build a canonical label, the authors define the concepts of a DFS code, the DFS Lexicographic Order, the minimum DFS code for a graph, and the DFS Code Tree.
Using these, the authors claim gSpan is able to quickly find frequent subgraphs without wasting resources on redundant candidates by recursively expanding frequent subgraphs one edge at a time and checking whether those subgraphs are frequent using an implicit TID list.
If the code created from a subgraph is not the subgraph's minimum code, it is immediately pruned, as the authors have proven in a technical report that this subgraph would already have been processed earlier in the algorithm's execution.

\\ \\

This paper seems like a high quality breakthrough in the field of frequent subgraph mining, but it's difficult to state this with confidence due to the density of the authors' technical writing.
For instance, the authors make claims and supply a theorem that are not substantiated in this paper.
The reader is instead directed to their non-peer reviewed technical report.
Their coverage of related works is lacking, only citing two other subgraph miners and two subtree miners with one-sentence descriptions.
In addition, there are some technical errors and notational inconsistencies that muddy up the clarity of their proposed algorithms and requisite definitions.
Performance-wise, the authors compared gSpan against FSG using similar datasets used by FSG, finding gSpan faster and less memory hogging than FSG.
However, their experimental evaluation seems to have been conducted hastily, only compare gSpan against FSG against one real-world dataset and a limited number of synthetic ones, all while ignoring AGM.
Regardless of these issues, the citation count and publication venue of this work indicate that gSpan is as beneficial as the authors claim.

	}
}

@inproceedings{Holder:1994:SDS:3000850.3000868,
 author = {Holder, Lawrence B. and Cook, Diane J. and Djoko, Surnjani},
 title = {Substructure Discovery in the SUBDUE System},
 booktitle = {Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining},
 series = {AAAIWS'94},
 year = {1994},
 location = {Seattle, WA},
 pages = {169--180},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=3000850.3000868},
 acmid = {3000868},
 publisher = {AAAI Press},
	annote = {

This paper proposes an extension to the authors' SUBDUE system, whereby they strive to compress directed, labeled multigraphs through the discovery and substitution of recurring - but not necessarily frequent - subgraphs through either exact or inexact matching.
A breadth-first search is used to generate candidate subgraphs whereby previously-found subgraphs are expanded one edge at a time.
These are then scored based on the reduction in the compressed graph's description length as well as optional guidance from background knowledge rules.
Ultimately, subgraphs that offer the best compression ratio and highest domain-specific score are identified.
Their algorithm has been found to prefer smaller, more frequent subgraphs over larger ones, but subsequent passes of SUBDUE may be performed on the previous pass's output graph so as to identify larger subgraphs.

\\ \\

The experimental analysis of SUBDUE focuses on the fields of chemical component analysis, object recognition in images, and CAD circuit analysis.
The experiments conducted appear limited in the insights that may be drawn from their system's performance, as the authors only offer the compression ratio achieved by SUBDUE when executed on the few datasets used.
There was no comparative analysis performed against other similar systems, which the authors identify a few in the related works section, nor do their experiments record useful performance metrics such as runtimes or the number/sizes of the subgraphs identified in their experiments.

\\ \\

Overall, the paper is well written but limited in the insights one may draw from the content alone.
By today's standards, it is flawed in the thoroughness of its experimental analysis and its inability to identify all frequently occurring subgraphs.
The authors claim that repeated executions of SUBDUE will render better results, but neglect to thoroughly demonstrate this through experimentation.
Since this work may have been the seminal work on frequent subgraph mining, it is understandable that the related work section is not entirely focused on previous works in this field.

	}
}

@article{KuramochiKarypis2004, 
  author={M. Kuramochi and G. Karypis}, 
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={An efficient algorithm for discovering frequent subgraphs}, 
  year={2004}, 
  volume={16}, 
  number={9}, 
  pages={1038-1051}, 
  keywords={computational complexity;data mining;graph theory;pattern recognition;very large databases;chemical compound data sets;data mining techniques;frequent itemset discovery algorithms;frequent pattern discovery problem;frequent subgraph discovery;graph data sets;scientific data sets;Chemical compounds;Data mining;Frequency;Itemsets;Labeling;65;Index Terms- Data mining;chemical compound data sets.;frequent pattern discovery;scientific data sets}, 
  doi={10.1109/TKDE.2004.33}, 
  ISSN={1041-4347}, 
  month={Sept},
  annote = {

This paper proposes a new algorithm, FSG, for mining frequent connected subgraphs in undirected transaction graphs.
The approach adopted by FSG is to generate candidate subgraphs in a breadth-first manner, representing generated candidates in canonical form and computing their frequency of occurrence using a number of speed-up strategies.
Novel contributions include 
  the level-wise join operation for generating candidates with reduced duplication; 
  a partitioning strategy aimed at quickly pruning candidates and relaxing the memory demands of Transaction ID lists;
  and a canonical labeling scheme that speeds up support calculations and reduces the number of subgraph isomorphism operations needed for a set of generated candidates, with extensions to assist graphs with low label diversity or high symmetry and regularity.
  
\\ \\

Through their experimental evaluations, the authors demonstrate the effectiveness and scalability of FSG when applied to real-world chemical datasets and synthetically generated transaction datasets.
These datasets are sufficiently diverse in properties so as to demonstrate FSG's performance on a few large transactions and many small transactions, both exhibiting low label diversity, as well as datasets with a varying degree of transactions, edges, frequent subgraph counts, and vertex-/edge-label diversity.
It was also noted that FSG does not perform well on graphs with low label diversity, but its' strategies aimed at reducing memory demands was successful when compared to the alternative approach.
Additionally, it appears as though graphs exhibiting high symmetry and regularity were not adequately tested.

\\ \\

Overall, the paper is very well written and easy to comprehend, with only a few typos and awkward grammatical structures.
The primary novelty of this work is through the canonical representation scheme, for which they provide proof of its correctness in the appendix.
The only concerning aspects of the paper is the absence of a comparative evaluation of FSG against related work and the presentation of some of the experimental results as tables, where the plotting of this data would have aided in a reader's understanding of FSG's scalability.
  
  }
}

@article{Jiang2013,
	abstract = {
	
Graph mining is an important research area within the domain of data mining.
The field of study concentrates on the identification of frequent subgraphs within graph data sets.
The research goals are directed at:
  (i) effective mechanisms for generating candidate subgraphs (without generating duplicates)
  and (ii) how best to process the generated candidate subgraphs so as to identify the desired frequent subgraphs in a way that is computationally efficient and procedurally effective.
This paper presents a survey of current research in the field of frequent subgraph mining, and proposed solutions to address the main research issues.

  },
  author = {Jiang, Chuntao and Coenen, Frans and Zito, Michele},
  doi = {10.1017/S0269888912000331},
  issn = {0269-8889},
  journal = {The Knowledge Engineering Review},
  month = {March},
  number = {01},
  pages = {75--105},
  title = {{A survey of frequent subgraph mining algorithms}},
  url = {http://www.journals.cambridge.org/abstract{\_}S0269888912000331},
  volume = {28},
  year = {2013},
  annote = {

This survey paper provides a comprehensive overview of 19 frequent subtree
 mining algorithms and 25 frequent subgraph mining algorithms published in the
 early to mid 2000s. To start off, the authors provide preliminary formalisms,
 brief descriptions of five notable (sub)graph isomorphism algorithms, and a
 high-level overview of the approaches adopted by frequent subgraph / tree 
 mining (FGM/FTM) algorithms, such as certain strategies to subgraph candidate 
 generation and canonical labelling representations of graphs and trees. From 
 there, the focus shifts to the state-of-the-art for FTM algorithms followed
 by those more generally applicable to FGM.
\\ \\
In their discussion on FTM algorithms, they categorize algorithms by the nature 
 of the input trees (e.g. unordered vs. ordered, free, hybrid, maximal, closed, 
 induced, and embedded), and further delineate them by numerous factors: the 
 method of search space traversal and candidate subtree generation; the method 
 of support computation and the data structures used therein; whether
 exact or inexact matching is applied for support calculation; and a mentioning of the 
 ranking of these algorithms in regards to the experimental evaluation from the 
 originating papers.
\\ \\
In their discussion on FGM algorithms, algorithms are categorized by whether 
 they are general purpose or pattern dependent, subcategorized by the exactness 
 of candidate matches, further subcategorized by the type of input graph (e.g. 
 transaction graphs or a single graph), and even further subcategorized by the 
 strategy for candidate generation (e.g. breadth-first searching of the search 
 space or depth-first). Their discussion focuses on the algorithmsâ€™ 
 utilized canonical representations, specific approaches to candidate 
 generation, special data structures to facilitate certain operations, and some critical comments 
 on the performance benefits and drawbacks as evident in the originating papers.
\\ \\
Overall, the paper is well written in its brevity, yet comprehensive in its coverage. However, 
 there are portions that impede the clarity of certain topics, as well as 
 typographical and technical errors sparsely scattered throughout. In addition, 
 although the paper is comprehensive in its coverage of FSM algorithms in the 
 early to mid 2000s, the latest papers discussed date to 2008, which leaves a 
 four year gap between their covered state-of-the-art and this article's 
 surveyed works. The authors indicate that only incremental improvements of 
 existing strategies had been proposed during that period of time with no new 
 significant proposals. However, it would have been appropriate to provide 
 acknowledgements to these minor improvements at least as an after-comment to 
 those solutions on which improvements were made.
  },
}
