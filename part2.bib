@inproceedings{Cheng:2009:IBS:1572272.1572290,
 author = {Cheng, Hong and Lo, David and Zhou, Yang and Wang, Xiaoyin and Yan, Xifeng},
 title = {Identifying Bug Signatures Using Discriminative Graph Mining},
 booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
 series = {ISSTA '09},
 year = {2009},
 isbn = {978-1-60558-338-9},
 location = {Chicago, IL, USA},
 pages = {141--152},
 numpages = {12},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bug signature, discriminative subgraph mining},
 annote = {
 
This paper applies the LEAP discriminative subgraph mining algorithm towards the problem of software bug localization.
The authors' approach operates on software behavior graphs, which compactly represents the execution steps performed by a given software based on provided input.
Given software that contains bugs, a set of software behavior graphs can be formed by running the software on a variety of test cases.
Each graph in the set is then classified as a faulty run or a successful run.
With the set of graphs partitioned by these classes, the LEAP algorithm identifies a subgraph that is most discriminative in classifying other graphs.
The authors use this discriminative subgraph to identify the location of a bug.

There are only two contributions of this paper: (1) representing a software's execution as a graph, and
(2) a naive extension of LEAP to generate the top $k$ most discriminative subgraphs from two sets of input graphs.
The claim that their approach allows "for imperfections in traces and slight variations of bug patterns" is not demonstrated in the paper.
%The authors claim their approach captures the \emph{context} of a software bug, but it does not capture the variable states as would intuitively be expected with the use of the word \emph{context}.
In my opinion, this work lacks sufficient novelty, clarity, insight, and experimental thoroughness required for academic publication.
Throughout the paper, there are numerous occasions of misused words and symbology and absent definitions that harm a reader's understanding.
The authors fail to define the similarity function that permits LEAP to skip over branches in the subgraph enumeration tree.
Their extension of LEAP is naive by re-running the algorithm $k$ times and building a list of each subgraph that is returned.
Cosmetically, their pseudocode of this extension appears faulty and inefficient in that it would to perform redundant subgraph enumerations across its $k$ executions of LEAP.
With regard to experimentation, the authors fail to summarize the Siemens dataset and their approach to running experiments so as to permit reproduction of their experiments.

 }
}


@incollection{Tang2010,
    author="Tang, Lei and Liu, Huan",
    editor="Aggarwal, Charu C. and Wang, Haixun",
    title="Graph Mining Applications to Social Network Analysis",
    booktitle="Managing and Mining Graph Data",
    year="2010",
    publisher="Springer US",
    address="Boston, MA",
    pages="487--513",
    annote = {
    
This chapter is easy to read, succinct in its discussions, and well organized.
Claims made throughout the discussion are properly cited and smoothly integrated.
On the grand scale, the discussion flows from a summary on the patterns and
characteristics found in real-world, large-scale social networks, moving on to
surveying techniques for detecting communities and evaluating the \emph{goodness}
of these detected community.
\\ \\
On graph patterns, common characteristics of large-scale networks are discussed.
Node degrees are often seen to follow a power law distribution in these networks,
resulting in social networks being classified as \emph{scale-free}.
This results in two other properties: the small-world phenomenon, where any two
pairs of nodes tend to be relatively close in a massive social network;
and community formation, where nodes tend to connect with some subset of nodes,
forming a community, more often than with outsiders.
Quantifying the small-world phenomenon can come through measuring a network's
diameter or approximating it through its effective eccentricity or 
characteristic path length, though each of these methods lack scalability
in massive networks.
\\ \\
When it comes to communities, a thorough and comprehensive discussion covers
measures on a community's connectivity through its clustering coefficient and
reviews a plethora of methods for mining communities in a given network.
Categories of these methods include the following:
\begin{itemize}
\item Node-centric: modularity, reachability, nodal degrees, and the ratio of intra-/intercommunity connections
\item Group-centric: group-holistic properties such as edge density
\item Network-centric: partitioning and clustering nodes through global optimization
 of vertex neighborhood similarities,
 minimum cuts to define community boundaries,
 block model comparison,
 modularity relative to a random network,
 and latent space mapping.
\item Hierarchical clustering: top-down through edge betweeness, bottom-up through modularity gain, and search-space traversal.
\end{itemize}
All throughout this discussion, remarks on the computational challenges of each method and alternative methods as work arounds are discussed.
Comparing and evaluating the detected communities of different methods then becomes necessary.
One may analyze and compare the ($k$-)cliques, $k$-clans, $k$-plexes, or $k$-cores of detected communities immediately.
Though rare, prior information such as ground truth or semantic labeling permits conventional classification measures to be used.
Without prior information, community modularity and link prediction can be used for measuring community \emph{goodness}.
\\ \\

The discussion ends with thoughts on future research into scalability, dynamic
 communities, integrating large-scale network patterns and heterogeneous connections
 for social network analysis, and an encouragement on demonstrating the usefulness
 of communities for applied problems.

    
    }
}




@incollection{Cheng2014,
    pages = {307-338},
    title= {Mining Graph Patterns},
    author={Cheng, Hong and Yan, Xifeng and Han, Jiawei},
    booktitle={Frequent Pattern Mining},
    publisher={Springer International Publishing},
    year = {2014},
    editor={Aggarwal, Charu C. and Han, Jiawei},
    address={Cham, Switzerland},
    annote = {
    
This chapter surveys research on frequent subgraph pattern mining, a more application-focused field within the area of frequent subgraph mining, as well as frequent subgraph mining in non-traditional graph models.
Frequent subgraph patterns are a subset of the frequent subgraphs
 found within a single massive graph or a transaction graph dataset,
 characterized as being more \emph{interesting} to a certain application domain than other frequent subgraphs.
By ignoring \emph{uninteresting} frequent subgraphs, 
 the computational and storage complexity
 of a graph mining operation is reduced.
The chapter begins with preliminary formalisms and brief reviews of the parent field on frequent subgraph mining.
Motivated by the computational bottleneck of these approaches, the discussion shifts focuses towards works on frequent subgraph pattern mining, and concludes with a review of approaches operating on graph streams and uncertain graphs. 

\\ \\
 
On the mining of subgraph patterns, the reviewed mining algorithms in this chapter target
    significant subgraphs (4 methods are reviewed),
    representative subgraphs (1 method),
    and various dense subgraphs:
        cliques (4 methods),
        $k$-cores (1 method),
        $k$-trusses (2 methods),
        dense neighborhood graphs (1 method),
        and dense bipartite subgraphs (1 method).
Significant subgraphs are frequent subgraphs that either exceed a threshold or maximize a user-defined objective function.
Representative subgraphs are a small subset of frequent subgraphs that can \emph{represent} many others by being sufficiently similar - a user-defined metric - to the other frequent subgraphs within a dataset.
A cliques is a subset of vertices from a graph that induce a complete subgraph; similarly, a quasi-clique induces a nearly-complete subgraph.
The $k$-core of a graph is the largest subgraph with all vertices being $k$-degree or more.
On $k$-trusses, dense neighborhood graphs, and dense bipartite graphs, the authors neglect to provide adequate definitions.
Discussions on the reviewed algorithms focus on each one's goal and a brief outlining of the various methods used to reach that goal,
with no discussions on the experimental performance of these methods.

\\ \\

The final two sections discusses mining techniques on two non-traditional graph models: graph streams and uncertain graphs.
A graph stream presents portions of a graph as only accessible in some sequential order, whether it be streaming of the edges of a graph (discussed in 2 works), dynamic updates to edge weights of a single large graph (1 work), or limiting access to a subset of graphs arriving in batches (1 work).
Uncertain graphs present their vertices and edges as probabilistic in existence.
The goals of the reviewed works are to discover highly reliable subgraphs and to mine subgraphs that have a sufficient probability of being frequent.

\\ \\

This work provides worthwhile discussions and detailed overviews of some of the research it surveys.
The preliminary formalisms in the beginning of most sections are succinct and clear in relaying to the reader an understanding of certain concepts.
However, the chapter is inconsistently organized, and some sections feel out of place and rushed while others dwell upon a work for too long or not long enough.
For instance, the discussion on LEAP, a work published by the authors of this chapter, goes on for five pages whereas other works have at most three-page discussions, some only receiving one paragraph.
Near the end, when the discussion shifts towards non-traditional graph models, there is a noticeable increase in typos and poorly written statements.

    }
}

@TECHREPORT{WondBaur2010,
  AUTHOR =        {Wong, Elisabeth A. and Baur, Brittany},
  TITLE =         {On Network Tools for Network Motif Finding: A Survey Study},
  INSTITUTION =   {Bio-Grid REU Program, University of Connecticut},
  ADDRESS =       {Storrs, Connecticut},
  YEAR  =         {2010},
  PAGES =         {21},
  ANNOTE =        {
  
This survey covers seven algorithms for mining and identifying motifs in biological networks,
 which are frequent subgraphs in a target network 
 that have a statistically significant frequency of occurrence
 higher than that observed in random networks.
To begin, a primer is given on the fundamental concepts used in motif motif:
 graph isomorphism and the computational challenges it brings,
 various measurement methods for computing a subgraph's frequency to identify motifs,
 the methods used to generate random graphs.
From there, the eight algorithms for motif mining are informally described,
 with the discussion covering each algorithm at a high level.

\\ \\

Algorithms are categorized based on the following properties:
 whether the algorithms are network-centric (i.e. find all motifs in a given target network)
 or motif-centric (i.e. determine if a given subgraph is a motif in a given target network);
 and whether the algorithms perform full enumeration or probabilistic enumeration.
Each summary begins by describing an algorithm's input parameters,
 the type of network they can operate on,
 the manner in which frequencies are counted (i.e. permissibility of overlapping nodes and edges),
 and the criteria for identifying network motifs.
Then, the steps and unique methods involved in each algorithm are outlined.
NeMoFINDER, Kavosh, and MA Visto are network-centric, full-enumeration miners using enumeration trees to build candidate motifs.
MFinder and FANMOD are similar, but offer probabilistic enumeration methods to reduce runtime at the cost of accuracy, with MFinder susceptible to biased sampling.
For motif-centric algorithms, Grochow and MODA aim to map \emph{query subgraphs} given as input onto a given target network so as to determine if they are motifs.
From the discussion on performance, MA Visto and MFinder were found to be computationally more expensive and unable to mine motifs larger than size-5.
NeMoFINDER and Kavosh, however, demonstrated the ability to find size-13 and size-10 motifs, respectively.
But, whereas NeMoFINDER took about 20 hours on a larger protein-protein interaction network and is restricted to operate only on undirected graphs, the more generally-applicable Kavosh took nearly 13 days to execute on a smaller yeast transcription network.
It should be noted that these findings come from different studies and thus could have been performed on computers of substantially different power.
It is suggested that FANMOD is a better option for error-tolerant motif mining, and MODA demonstrated a faster runtime and classified larger motifs than Grochow.

\\ \\

This work was completed as a technical report following the completion of an undergraduate research program, and although it was not peer reviewed, it did provide some worthwhile information about the proposed algorithms in the papers it surveyed.
However, there are flaws that hinder a reader's clear understanding of how these algorithms work and compare to one another, and limit the insights that may be drawn from the survey.
The experimental analysis section requires major improvements as it appears as though the authors simply extracted the experimental findings of the sourced works with little effort in tying the findings together.
  
  }
}











@inproceedings{SUBDUE1994,
 author = {Holder, Lawrence B. and Cook, Diane J. and Djoko, Surnjani},
 title = {Substructure Discovery in the SUBDUE System},
 booktitle = {Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining},
 series = {AAAIWS '94},
 year = {1994},
 location = {Seattle, WA},
 pages = {169--180},
 numpages = {12},
 acmid = {3000868},
 publisher = {AAAI Press},
	annote = {

This paper proposes an extension to the authors' SUBDUE system, whereby they strive to compress directed, labeled multigraphs through the discovery and substitution of recurring - but not necessarily frequent - subgraphs through either exact or inexact matching.
A BFS traversal generates candidate subgraphs from previously-found subgraphs, expanding them one edge at a time.
These candidates are then scored based on the reduction in the compressed graph's description length as well as optional guidance from background knowledge rules.
Ultimately, subgraphs that offer the minimum description length (MDL) and highest domain-specific score are identified.
Their algorithm has been found to prefer smaller, more frequent subgraphs over larger ones, but subsequent passes of SUBDUE may be performed on a previous pass's output so as to identify larger subgraphs.

\\ \\

The experimental analysis of SUBDUE focuses on the fields of chemical component analysis, object recognition in images, and CAD circuit analysis.
The conducted experiments appear limited in the insights that may be drawn from their system's performance, as the authors only offer the compression ratio achieved by SUBDUE when executed on the few datasets used.
There was no comparative analysis performed against other similar systems identified in the related works section, nor did their experiments record useful performance metrics such as runtimes or the number/sizes of the subgraphs identified in their experiments.

\\ \\

Overall, the paper is well written but limited in the insights one may draw from the content alone.
By today's standards, it is flawed in the thoroughness of its experimental analysis and its inability to identify all frequently occurring subgraphs.
The authors claim that repeated executions of SUBDUE will render better results, but neglect to thoroughly demonstrate this through experimentation.

	}
}


@inproceedings{FFSM2003,
  author = {Huan, Jun and Wang, Wei and Prins, Jan},
  title = {Efficient Mining of Frequent Subgraphs in the Presence of Isomorphism},
  booktitle={Third IEEE International Conference on Data Mining}, 
  series = {ICDM '03},
  year = {2003},
  isbn = {0-7695-1978-4},
  pages = {549-552},
  publisher = {IEEE Computer Society},
  address = {Washington, DC, USA},
	annote = {

FFSM operates on labeled undirected transaction graphs in a BFS manner, with the targeted goal of eliminating redundantly-generated subgraphs while the search space is traversed, thereby reducing the algorithm's runtime.
This is accomplished through the usage of the canonical adjacency matrix (CAM) of a candidate subgraph as a means of uniquely representing it and generating more candidates.
Each graph is represented as a edge/node-labeled adjacency matrix, whereby the CAM of a graph is its adjacency matrix with the lexicographic-maximal encoding.
The encoding is simple: concatenate the rows of the lower-triangular into a flat string.
This scheme offers simple relationships between a represented graph and its subgraphs, leading to efficient candidate generation through joins and extensions of frequent subgraphs and quick pruning if a generated candidate is not in CAM form.

\\ \\

In terms of quality, this paper needs to further elaborate on the join and extension operations and the usefulness of a CAM's embedding set, as it is unclear how these operations and concepts are performed and useful.
Most of the rigorous material is relocated into a non-peer reviewed technical report, including the proofs of a theorem and several important corollaries and procedural pseudocode used in the main algorithm.
The experimental evaluation of FFSM indicates that its runtimes beat those of gSpan, although only one set of experiments is demonstrated in this paper with further experiments detailed in the aforementioned technical report.

	}
} 


@article{Jiang2013,
	abstract = {
	
Graph mining is an important research area within the domain of data mining.
The field of study concentrates on the identification of frequent subgraphs within graph data sets.
The research goals are directed at:
  (i) effective mechanisms for generating candidate subgraphs (without generating duplicates)
  and (ii) how best to process the generated candidate subgraphs so as to identify the desired frequent subgraphs in a way that is computationally efficient and procedurally effective.
This paper presents a survey of current research in the field of frequent subgraph mining, and proposed solutions to address the main research issues.

  },
  author = {Jiang, Chuntao and Coenen, Frans and Zito, Michele},
  doi = {10.1017/S0269888912000331},
  issn = {0269-8889},
  journal = {The Knowledge Engineering Review},
  month = {March},
  number = {01},
  pages = {75--105},
  title = {{A survey of frequent subgraph mining algorithms}},
  volume = {28},
  year = {2013},
  annote = {

This survey paper provides a comprehensive overview of 19 frequent subtree
 mining algorithms and 25 frequent subgraph mining algorithms published in the
 early to mid 2000s. To start off, the authors provide preliminary formalisms,
 brief descriptions of five notable (sub)graph isomorphism algorithms, and a
 high-level overview of the approaches adopted by frequent subgraph / tree 
 mining (FGM/FTM) algorithms, such as certain strategies to candidate subgraph  
 generation and canonical labelling representations of graphs and trees. From 
 there, the focus shifts to the state-of-the-art for FTM algorithms followed
 by those more generally applicable to FGM.
\\ \\
In their discussion on FTM algorithms, they categorize algorithms by the nature 
 of the input trees (e.g. unordered vs. ordered, free, hybrid, maximal, closed, 
 induced, and embedded), and further delineate them by numerous factors: the 
 method of search space traversal and candidate subtree generation; the method 
 of support computation and the data structures used therein; whether
 exact or inexact matching is applied for support calculation; and a mentioning of the 
 ranking of these algorithms in regards to the experimental evaluation from the 
 originating papers.
\\ \\
In their discussion on FGM algorithms, algorithms are categorized by whether 
 they are general purpose or pattern dependent, subcategorized by the exactness 
 of candidate matches, further subcategorized by the type of input graph (e.g. 
 transaction graphs or a single graph), and even further subcategorized by the 
 strategy for candidate generation (e.g. breadth-first searching of the search 
 space or depth-first). Their discussion focuses on the algorithms' 
 utilized canonical representations, specific approaches to candidate 
 generation, special data structures to facilitate certain operations, and some critical comments 
 on the performance benefits and drawbacks as evident in the originating papers.
\\ \\
Overall, the paper is well written in its brevity, yet comprehensive in its coverage. However, 
 there are portions that impede the clarity of certain topics, as well as 
 typographical and technical errors sparsely scattered throughout.
 Although the paper is comprehensive in its coverage of FSM algorithms in the 
 early to mid 2000s, the latest papers discussed date to 2008, which leaves a 
 four year gap between their covered state-of-the-art and this article's 
 publication date. The authors indicate that only incremental improvements of 
 existing strategies had been proposed during that period of time with no new 
 significant proposals. However, it would have been appropriate to provide 
 acknowledgements to these minor improvements at least as an after-comment to 
 those solutions on which improvements were made.
  },
}


@article{KuramochiKarypis2004, 
  author={M. Kuramochi and G. Karypis}, 
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={An efficient algorithm for discovering frequent subgraphs}, 
  year={2004}, 
  volume={16}, 
  number={9}, 
  pages={1038-1051}, 
  keywords={computational complexity;data mining;graph theory;pattern recognition;very large databases;chemical compound data sets;data mining techniques;frequent itemset discovery algorithms;frequent pattern discovery problem;frequent subgraph discovery;graph data sets;scientific data sets;Chemical compounds;Data mining;Frequency;Itemsets;Labeling;65;Index Terms- Data mining;chemical compound data sets.;frequent pattern discovery;scientific data sets}, 
  doi={10.1109/TKDE.2004.33}, 
  ISSN={1041-4347}, 
  month={Sept},
  annote = {

FSG targets the frequent connected subgraphs residing in undirected transaction graphs through a BFS candidate generation scheme.
Each candidate is represented in canonical form and their occurrence frequency is computed a number of speed-up strategies.
Novel contributions include 
  the level-wise join operation for generating candidates with reduced duplication; 
  a partitioning strategy aimed at quickly pruning candidates and relaxing the memory demands of transaction ID lists;
  and a canonical labeling scheme that speeds up support calculations and reduces the number of needed subgraph isomorphism operations.
Extensions of this labeling scheme are offered to assist graphs with low label diversity or high symmetry and regularity.
  
\\ \\

Through experimental evaluations, the authors demonstrate the effectiveness and scalability of FSG when applied to real-world chemical datasets and synthetically generated transaction datasets.
These datasets are sufficiently diverse in properties so as to demonstrate FSG's performance on a few real-world large transactions, many real-world small transactions, and highly diverse synthetic transactions.
FSG does not perform well on graphs with low label diversity, but its' strategies aimed at reducing memory demands were successful when compared to the alternative approach.
Graphs exhibiting high symmetry and regularity, however, were not adequately tested, thus flawing that portion of their contributions.

\\ \\

Overall, the paper is very well written and easy to comprehend, with only a few typos and awkward grammatical statements.
The primary novelty of this work is through the canonical representation scheme for which they provide proof of its correctness in the appendix.
The only concerning aspects of the paper is the absence of a comparative evaluation of FSG against related work and the tabular presentation of some of the experimental results, where the plotting of this data would have aided in a reader's understanding of FSG's scalability.
  
  }
}


@INPROCEEDINGS{1184038, 
	author={Xifeng Yan and Jiawei Han}, 
	booktitle={2002 IEEE International Conference on Data Mining, 2002. Proceedings.}, 
	title={gSpan: graph-based substructure pattern mining}, 
	year={2002}, 
	pages={721-724}, 
	keywords={data mining;tree searching;algorithm;canonical label;depth-first search strategy;frequent connected subgraph mining;frequent graph-based pattern mining;frequent substructure discovery;gSpan;graph datasets;graph-based substructure pattern mining;lexicographic order;performance study;unique minimum DFS code;Chemical compounds;Computer science;Costs;Data mining;Data structures;Graphics;Itemsets;Kernel;Testing;Tree graphs}, 
	doi={10.1109/ICDM.2002.1184038}, 
	month={},
	annote = {

gSpan targets undirected transaction graph datasets to find frequent subgraphs in a DFS manner.
The main contribution of this paper is their new canonical labeling system based on a code generated through a DFS traversal of a graph.
To build a canonical label, the authors define the concepts of a DFS code, the DFS Lexicographic Order, the minimum DFS code for a graph, and the DFS Code Tree.
Using these, gSpan is able to quickly find frequent subgraphs without wasting resources on redundant candidates.
Frequent subgraphs are recursively expanded one edge at a time and checked for sufficient support using the TID list from the subgraph generating it.
If the code created from a subgraph is not the subgraph's minimum code, it is immediately pruned as it would have previously been processed.

\\ \\

This paper seems like a high quality breakthrough in the field of frequent subgraph mining, but it's difficult to state this with confidence due to the density of the authors' technical writing.
For instance, the authors make claims and state a theorem without substantiation in this paper.
The reader is instead directed to their non-peer reviewed technical report.
Their coverage of related works is lacking, only citing two other subgraph miners and two subtree miners with brief remarks.
In addition, there are some technical errors and notational inconsistencies that muddy up the clarity of their defined concepts and algorithms.
Performance-wise, the authors compared gSpan against FSG using similar datasets as used by FSG's authors, finding gSpan faster and less memory hogging than FSG.
However, their experimental evaluation seems to have been conducted hastily, only comparing gSpan against FSG using one real-world dataset and a limited number of synthetic ones, all while ignoring AGM and other related works.
Regardless of these issues, the citation count and publication venue of this work indicate that gSpan is as beneficial as the authors claim.

	}
}