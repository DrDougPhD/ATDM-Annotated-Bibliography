@inproceedings{Cheng:2009:IBS:1572272.1572290,
 author = {Cheng, Hong and Lo, David and Zhou, Yang and Wang, Xiaoyin and Yan, Xifeng},
 title = {Identifying Bug Signatures Using Discriminative Graph Mining},
 booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
 series = {ISSTA '09},
 year = {2009},
 isbn = {978-1-60558-338-9},
 location = {Chicago, IL, USA},
 pages = {141--152},
 numpages = {12},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {bug signature, discriminative subgraph mining},
 annote = {
 
This paper applies the LEAP discriminative subgraph mining algorithm towards the problem of software bug localization.
The authors' approach operates on software behavior graphs, which compactly represents the execution steps performed by a given software based on provided input.
Given software that contains bugs, a set of software behavior graphs can be formed by running the software on a variety of test cases.
Each graph in the set is then classified as a faulty run or a successful run.
With the set of graphs partitioned by these classes, the LEAP algorithm identifies a subgraph that is most discriminative in classifying other graphs.
The authors use this discriminative subgraph to identify the location of a bug.

There are only two contributions of this paper: (1) representing a software's execution as a graph, and
(2) a naive extension of LEAP to generate the top $k$ most discriminative subgraphs from two sets of input graphs.
The claim that their approach allows "for imperfections in traces and slight variations of bug patterns" is not demonstrated in the paper.
%The authors claim their approach captures the \emph{context} of a software bug, but it does not capture the variable states as would intuitively be expected with the use of the word \emph{context}.
In my opinion, this work lacks sufficient novelty, clarity, insight, and experimental thoroughness required for academic publication.
Throughout the paper, there are numerous occasions of misused words and symbology and absent definitions that harm a reader's understanding.
The authors fail to define the similarity function that permits LEAP to skip over branches in the subgraph enumeration tree.
Their extension of LEAP is naive by re-running the algorithm $k$ times and building a list of each subgraph that is returned.
Cosmetically, their pseudocode of this extension appears faulty and inefficient in that it would to perform redundant subgraph enumerations across its $k$ executions of LEAP.
With regard to experimentation, the authors fail to summarize the Siemens dataset and their approach to running experiments so as to permit reproduction of their experiments.

 }
}


@incollection{Cheng2014,
    pages = {307-338},
    title= {Mining Graph Patterns},
    author={Cheng, Hong and Yan, Xifeng and Han, Jiawei},
    booktitle={Frequent Pattern Mining},
    publisher={Springer International Publishing},
    year = {2014},
    editor={Aggarwal, Charu C. and Han, Jiawei},
    address={Cham, Switzerland},
    annote = {
    
This chapter surveys research on frequent subgraph pattern mining, a more application-focused field within the area of frequent subgraph mining, as well as frequent subgraph mining in non-traditional graph models.
Frequent subgraph patterns are a subset of the frequent subgraphs
 found within a single massive graph or a transaction graph dataset,
 characterized as being more \emph{interesting} to a certain application domain than other frequent subgraphs.
By ignoring \emph{uninteresting} frequent subgraphs, 
 the computational and storage complexity
 of a graph mining operation is reduced.
The chapter begins with preliminary formalisms and brief reviews of the parent field on frequent subgraph mining.
Motivated by the computational bottleneck of these approaches, the discussion shifts focuses towards works on frequent subgraph pattern mining, and concludes with a review of approaches operating on graph streams and uncertain graphs. 

\\ \\
 
On the mining of subgraph patterns, the reviewed mining algorithms in this chapter target
    significant subgraphs (4 methods are reviewed),
    representative subgraphs (1 method),
    and various dense subgraphs:
        cliques (4 methods),
        $k$-cores (1 method),
        $k$-trusses (2 methods),
        dense neighborhood graphs (1 method),
        and dense bipartite subgraphs (1 method).
Significant subgraphs are frequent subgraphs that either exceed a threshold or maximize a user-defined objective function.
Representative subgraphs are a small subset of frequent subgraphs that can \emph{represent} many others by being sufficiently similar - a user-defined metric - to the other frequent subgraphs within a dataset.
A cliques is a subset of vertices from a graph that induce a complete subgraph; similarly, a quasi-clique induces a nearly-complete subgraph.
The $k$-core of a graph is the largest subgraph with all vertices being $k$-degree or more.
On $k$-trusses, dense neighborhood graphs, and dense bipartite graphs, the authors neglect to provide adequate definitions.
Discussions on the reviewed algorithms focus on each one's goal and a brief outlining of the various methods used to reach that goal,
with no discussions on the experimental performance of these methods.

\\ \\

The final two sections discusses mining techniques on two non-traditional graph models: graph streams and uncertain graphs.
A graph stream presents portions of a graph as only accessible in some sequential order, whether it be streaming of the edges of a graph (discussed in 2 works), dynamic updates to edge weights of a single large graph (1 work), or limiting access to a subset of graphs arriving in batches (1 work).
Uncertain graphs present their vertices and edges as probabilistic in existence.
The goals of the reviewed works are to discover highly reliable subgraphs and to mine subgraphs that have a sufficient probability of being frequent.

\\ \\

This work provides worthwhile discussions and detailed overviews of some of the research it surveys.
The preliminary formalisms in the beginning of most sections are succinct and clear in relaying to the reader an understanding of certain concepts.
However, the chapter is inconsistently organized, and some sections feel out of place and rushed while others dwell upon a work for too long or not long enough.
For instance, the discussion on LEAP, a work published by the authors of this chapter, goes on for five pages whereas other works have at most three-page discussions, some only receiving one paragraph.
Near the end, when the discussion shifts towards non-traditional graph models, there is a noticeable increase in typos and poorly written statements.

    }
}


@article{Elseidy:2014:GFS:2732286.2732289,
 author = {Elseidy, Mohammed and Abdelhamid, Ehab and Skiadopoulos, Spiros and Kalnis, Panos},
 title = {GraMi: Frequent Subgraph and Pattern Mining in a Single Large Graph},
 journal = {Proc. VLDB Endow.},
 issue_date = {March 2014},
 volume = {7},
 number = {7},
 month = {March},
 year = {2014},
 issn = {2150-8097},
 pages = {517--528},
 numpages = {12},
 publisher = {VLDB Endowment},
    annote = {

GraMi is designed to return subgraph and pattern templates that occur with sufficient frequency in a single directed or undirected labelled graph.
Specifically, it doesn't return the mappings of these templates, but rather just the set of subgraph patterns that are frequent.
It operates in a breadth-first search manner, beginning with frequent edges and building subgraphs by extending a node in a frequent subgraph with a valid frequent edge.
A candidate subgraph's support is then computed using a minimum image based (MNI) support metric, which limits a set of overlapping subgraph instances to be counted as one occurrence.
GraMi's approach to subgraph isomorphism is to transform it into a constraint satisfaction problem (CSP), a formulation similar to an optimization problem but with the objective function omitted.
Solving a subgraph-isomorphism CSP results in a feasible solution that represents one mapping of a subgraph onto the graph.
\\ \\
Various speed-up strategies are implemented through a number of approaches.
(1) Subgraph isomorphism is halted when $\tau$, the minimum support threshold, are located.
(2) In the hopes of quickly pruning a candidate subgraph quickly, short-circuit evaluation is approximately emulated via a \emph{lazy search}, where the search for $\tau$ mappings of a node in a candidate subgraph is postponed if it takes too long.
Finding a node that has fewer than $\tau$ mappings implies the candidate subgraph is not frequent;
(3) The search space for node mappings, a subproblem of subgraph isomorphism, is shrunk for future candidate subgraphs by storing invalid node mappings in a hash table for each generated subgraph (\emph{push-down pruning} and \emph{automorphism} processing).
GraMi is further extended to perform pattern mining and constraint-based subgraph mining, called CGraMi, for structural and semantic constraints.
The authors also offer an approximate version, called AGraMi, that returns a subset of frequent subgraphs.
\\ \\
Through experimentation, GraMi was demonstrated to execute faster and consume less memory that GrowStore, an algorithm based on gSpan using MNI-based support.
A few experiments were run on very large graphs (millions of nodes), but most of GraMi's capabilities were demonstrated on smaller graphs (thousands of nodes).
AGraMi's speed was demonstrated to be faster than GraMi's, as was CGraMi's ability to detect larger frequent subgraph patterns.
Each speed-up strategy was demonstrated to contribute to these performance improvements.
Finally, GraMi's speed-up strategies were compared against using GraphQL, a state-of-the-art frequency evaluation function, and found to execute faster.
\\ \\
This paper is published in the top journal for database systems, VLDB, but the paper still lacks theoretical and experimental thoroughness, and also presents many vague and undefined terms, for me to consider it a good quality paper.
The author's representation of the problem as a CSP, although initially awkward on the first reading, brings some clarity into defining their algorithm.
However, the authors neglect to analyze the storage complexity of their algorithm, which becomes an issue when single graphs become prohibitively large.
Most of their demonstrated experiments are on smaller graph datasets, with only a few plots evaluating GraMi and GraphStore on multi-million-node graphs.
In searching for more information on GraphStore, the authors failed to provide a citation to its implementation.
Seeing as GraphStore is based on gSpan, which operates on transactional graph datasets, I am left to wonder if their comparisons were appropriate.
Also, for AGraMi, there is a significant flaw in the design of the iteration timeout function $f(\alpha)$ resulting in either it never halting a search or it being dominated by the undefined constant $\beta$, which the authors neglect to define in their experiments.
With AGraMi's perfect performance at $\alpha \approx 10^{-4}$, I suspect the authors favored experimental results that embellished GraMi's capabilities.

    }
}


@incollection{Tang2010,
    author="Tang, Lei and Liu, Huan",
    editor="Aggarwal, Charu C. and Wang, Haixun",
    title="Graph Mining Applications to Social Network Analysis",
    booktitle="Managing and Mining Graph Data",
    year="2010",
    publisher="Springer US",
    address="Boston, MA",
    pages="487--513",
    annote = {
    
This chapter is easy to read, succinct in its discussions, and well organized.
Claims made throughout the discussion are properly cited and smoothly integrated.
On the grand scale, the discussion flows from a summary on the patterns and
characteristics found in real-world, large-scale social networks, moving on to
surveying techniques for detecting communities and evaluating the \emph{goodness}
of these detected community.
\\ \\
On graph patterns, common characteristics of large-scale networks are discussed.
Node degrees are often seen to follow a power law distribution in these networks,
resulting in social networks being classified as \emph{scale-free}.
This results in two other properties: the small-world phenomenon, where any two
pairs of nodes tend to be relatively close in a massive social network;
and community formation, where nodes tend to connect with some subset of nodes,
forming a community, more often than with outsiders.
Quantifying the small-world phenomenon can come through measuring a network's
diameter or approximating it through its effective eccentricity or 
characteristic path length, though each of these methods lack scalability
in massive networks.
\\ \\
When it comes to communities, a thorough and comprehensive discussion covers
measures on a community's connectivity through its clustering coefficient and
reviews a plethora of methods for mining communities in a given network.
Categories of these methods include the following:
\begin{itemize}
\item Node-centric: modularity, reachability, nodal degrees, and the ratio of intra-/intercommunity connections
\item Group-centric: group-holistic properties such as edge density
\item Network-centric: partitioning and clustering nodes through global optimization
 of vertex neighborhood similarities,
 minimum cuts to define community boundaries,
 block model comparison,
 modularity relative to a random network,
 and latent space mapping.
\item Hierarchical clustering: top-down through edge betweeness, bottom-up through modularity gain, and search-space traversal.
\end{itemize}
All throughout this discussion, remarks on the computational challenges of each method and alternative methods as work arounds are discussed.
Comparing and evaluating the detected communities of different methods then becomes necessary.
One may analyze and compare the ($k$-)cliques, $k$-clans, $k$-plexes, or $k$-cores of detected communities immediately.
Though rare, prior information such as ground truth or semantic labeling permits conventional classification measures to be used.
Without prior information, community modularity and link prediction can be used for measuring community \emph{goodness}.
\\ \\

The discussion ends with thoughts on future research into scalability, dynamic
 communities, integrating large-scale network patterns and heterogeneous connections
 for social network analysis, and an encouragement on demonstrating the usefulness
 of communities for applied problems.

    
    }
}




@TECHREPORT{WondBaur2010,
  AUTHOR =        {Wong, Elisabeth A. and Baur, Brittany},
  TITLE =         {On Network Tools for Network Motif Finding: A Survey Study},
  INSTITUTION =   {Bio-Grid REU Program, University of Connecticut},
  ADDRESS =       {Storrs, Connecticut},
  YEAR  =         {2010},
  PAGES =         {21},
  ANNOTE =        {
  
This survey covers seven algorithms for mining and identifying motifs in biological networks,
 which are frequent subgraphs in a target network 
 that have a statistically significant frequency of occurrence
 higher than that observed in random networks.
To begin, a primer is given on the fundamental concepts used in motif motif:
 graph isomorphism and the computational challenges it brings,
 various measurement methods for computing a subgraph's frequency to identify motifs,
 the methods used to generate random graphs.
From there, the eight algorithms for motif mining are informally described,
 with the discussion covering each algorithm at a high level.

\\ \\

Algorithms are categorized based on the following properties:
 whether the algorithms are network-centric (i.e. find all motifs in a given target network)
 or motif-centric (i.e. determine if a given subgraph is a motif in a given target network);
 and whether the algorithms perform full enumeration or probabilistic enumeration.
Each summary begins by describing an algorithm's input parameters,
 the type of network they can operate on,
 the manner in which frequencies are counted (i.e. permissibility of overlapping nodes and edges),
 and the criteria for identifying network motifs.
Then, the steps and unique methods involved in each algorithm are outlined.
NeMoFINDER, Kavosh, and MA Visto are network-centric, full-enumeration miners using enumeration trees to build candidate motifs.
MFinder and FANMOD are similar, but offer probabilistic enumeration methods to reduce runtime at the cost of accuracy, with MFinder susceptible to biased sampling.
For motif-centric algorithms, Grochow and MODA aim to map \emph{query subgraphs} given as input onto a given target network so as to determine if they are motifs.
From the discussion on performance, MA Visto and MFinder were found to be computationally more expensive and unable to mine motifs larger than size-5.
NeMoFINDER and Kavosh, however, demonstrated the ability to find size-13 and size-10 motifs, respectively.
But, whereas NeMoFINDER took about 20 hours on a larger protein-protein interaction network and is restricted to operate only on undirected graphs, the more generally-applicable Kavosh took nearly 13 days to execute on a smaller yeast transcription network.
It should be noted that these findings come from different studies and thus could have been performed on computers of substantially different power.
It is suggested that FANMOD is a better option for error-tolerant motif mining, and MODA demonstrated a faster runtime and classified larger motifs than Grochow.

\\ \\

This work was completed as a technical report following the completion of an undergraduate research program, and although it was not peer reviewed, it did provide some worthwhile information about the proposed algorithms in the papers it surveyed.
However, there are flaws that hinder a reader's clear understanding of how these algorithms work and compare to one another, and limit the insights that may be drawn from the survey.
The experimental analysis section requires major improvements as it appears as though the authors simply extracted the experimental findings of the sourced works with little effort in tying the findings together.
  
  }
}
